---
title: "AUS Weather"
author: "Tucker Morgan - tlm2152"
date: "3/17/2022"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Quickly looking at the Australian weather dataset. The goal here would be to predict `RainTomorrow`, with each day being its own observation.
```{r set up and pulling data, message = FALSE}
library(tidyverse)

weather_aus <- read_csv("./AUSweather/weatherAUS.csv")
skimr::skim(weather_aus)
```

```{r looking at na values}
comp_data <- 
  weather_aus %>% 
  na.omit()

nrow(comp_data)
nrow(comp_data) / nrow(weather_aus)
```

Unfortunately, looks like the majority of days have some sort of missing data. Using this dataset would require extensive imputation. I imagine it wouldn't be too difficult to make a more complete dataset for this. Maybe using NOAA data and creating a variable that indicates rain the next day... a task for another occasion.

```{r skimming full data}
skimr::skim(comp_data)
```

But we do retain 3,416 unique dates, which is very close to the same number of unique dates in the full dataset. We lose almost half of our locations, indicating some problematic geographies. We would want to remove `Location`, and we would need to code `WindGustDir` and its kin somehow. Not sure if factorization would be the best route or not.

What's the breakout of "Yes" vs "No" for our outcome?
```{r counting raindrops}
comp_data %>% 
  filter(RainTomorrow == "Yes") %>% 
  nrow() 

comp_data %>% 
  filter(RainTomorrow == "Yes") %>% 
  nrow()/ nrow(comp_data)
```

Hmm... 22% positivity is pretty good! Might be usable. I'm really not sure if it matters that we exclude most days. We seem to have a large number of days with full data and a seemingly reasonable frequency.

```{r counting rain again}
weather_aus %>% 
  filter(RainTomorrow == "Yes") %>% 
  nrow()/ nrow(weather_aus)
```

Very similar percentages!! So missing data may not be related to whether it rains or not...